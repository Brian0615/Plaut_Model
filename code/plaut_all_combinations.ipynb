{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "# Plaut_Model/code/plaut_all_combinations\n",
    "\n",
    "### Purpose\n",
    "To create all possible combinations based on the Plaut grapheme onsets, vowels, and codas\n",
    "\n",
    "### Date Created\n",
    "March 27, 2020\n",
    "***\n",
    "### Revisions\n",
    "* Mar 27, 2020 - File created with initial code\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mappings for Graphemes\n",
    "grapheme_onset = ['Y', 'S', 'P', 'T', 'K', 'Q', 'C', 'B', 'D', 'G', 'F', 'V', 'J', 'Z',\n",
    "                  'L', 'M', 'N', 'R', 'W', 'H', 'CH', 'GH', 'GN', 'PH', 'PS', 'RH', 'SH', 'TH', 'TS', 'WH']\n",
    "grapheme_vowel = ['E', 'I', 'O', 'U', 'A', 'Y', 'AI', 'AU', 'AW', 'AY', 'EA', 'EE', 'EI',\n",
    "                  'EU', 'EW', 'EY', 'IE', 'OA', 'OE', 'OI', 'OO', 'OU', 'OW', 'OY', 'UE', 'UI', 'UY']\n",
    "grapheme_codas = ['H', 'R', 'L', 'M', 'N', 'B', 'D', 'G', 'C', 'X', 'F', 'V', 'J', 'S', 'Z', 'P', 'T', 'K', 'Q', 'BB', 'CH', 'CK', 'DD', 'DG',\n",
    "                  'FF', 'GG', 'GH', 'GN', 'KS', 'LL', 'NG', 'NN', 'PH', 'PP', 'PS', 'RR', 'SH', 'SL', 'SS', 'TCH', 'TH', 'TS', 'TT', 'ZZ', 'U', 'E', 'ES', 'ED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize empty lists\n",
    "orths = []\n",
    "graphemes = []\n",
    "types = []\n",
    "\n",
    "# find graphemes and types for every possible combination\n",
    "for i in itertools.product(grapheme_onset, grapheme_vowel, grapheme_codas):\n",
    "    orths.append(\"\".join(i))\n",
    "    graphemes.append(i)\n",
    "    types.append('CMPLX' if (len(i[0]) > 1 or len(i[1]) > 1 or len(i[2])> 1) else 'SIMP')\n",
    "\n",
    "# use numpy array for easier indexing\n",
    "graphemes = np.array(graphemes)\n",
    "\n",
    "# create dataset\n",
    "dataset = pd.DataFrame(data={'orth': orths,\n",
    "                            'g_onset': graphemes[:, 0],\n",
    "                            'g_vowel': graphemes[:, 1],\n",
    "                            'g_coda': graphemes[:, 2],\n",
    "                            'type': types,\n",
    "                            'freq': np.full(len(orths), 2),\n",
    "                            'log_freq': np.full(len(orths), np.log(2))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/BrianLam/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:61: FutureWarning: Series.nonzero() is deprecated and will be removed in a future version.Use Series.to_numpy().nonzero() instead\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# initialize empty list\n",
    "grapheme_codes = []\n",
    "\n",
    "# define grapheme sets, and word grapheme sets\n",
    "grapheme_sets = [grapheme_onset, grapheme_vowel, grapheme_codas]\n",
    "word_graphemes = [dataset['g_onset'], dataset['g_vowel'], dataset['g_coda']]\n",
    "\n",
    "'''\n",
    "for each grapheme type:\n",
    "  - create an empty matrix\n",
    "  \n",
    "  - for each grapheme inside that grapheme type\n",
    "      > find the indexes of the words that have that graphemex\n",
    "      > flag it in the empty matrix (i.e. set as 1)\n",
    "      \n",
    "      > if it is a complex grapheme (more than one letter)\n",
    "         > repeat above process for the individual letters of the grapheme\n",
    "           if the individual letter is also a grapheme of that type\n",
    "  - add the completed matrix to the list\n",
    "concatenate to obtain matrix of grapheme vectors of all words\n",
    "'''\n",
    "for g_set, wg in zip(grapheme_sets, word_graphemes):\n",
    "    grapheme_code = np.zeros((len(wg), len(g_set)), dtype=int)\n",
    "    \n",
    "    for g_index, grapheme in zip(range(len(g_set)), g_set):\n",
    "        w_index = np.argwhere(wg == grapheme)\n",
    "        grapheme_code[w_index, g_index] = 1\n",
    "        \n",
    "        if len(grapheme_onset) > 1:\n",
    "            for sg in grapheme:\n",
    "                try:\n",
    "                    sg_index = g_set.index(sg)\n",
    "                    grapheme_code[w_index, sg_index] = 1\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "    grapheme_codes.append(grapheme_code)\n",
    "grapheme_codes = np.hstack(grapheme_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add grapheme vectors to dataset\n",
    "dataset['graphemes'] = list(grapheme_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataset to csv file\n",
    "dataset.to_csv(r'../dataset/all_comb/plaut_all_comb_base.csv', index_label='word_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
