{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_helper(word, slot_set):\n",
    "    code = [0 for i in range(len(slot_set))]\n",
    "                             \n",
    "    while True:\n",
    "        if word[0:3] in slot_set: # check if triple letter slot\n",
    "            code[slot_set.index(word[0:3])] = 1\n",
    "            for i in [word[0:1], word[1:2], word[2:3], word[0:2], word[1:3]]: # check breakdown\n",
    "                if i in slot_set:\n",
    "                    code[slot_set.index(i)] = 1\n",
    "            word = word[3:]\n",
    "        elif word[0:2] in slot_set: # check if double letter slot\n",
    "            code[slot_set.index(word[0:2])] = 1\n",
    "            for i in [word[0:1], word[1:2]]: # check breakdown\n",
    "                if i in slot_set:\n",
    "                    code[slot_set.index(i)] = 1\n",
    "            word = word[2:]\n",
    "        elif word[0:1] in slot_set: # check if single letter slot\n",
    "            code[slot_set.index(word[0])] = 1\n",
    "            word = word[1:]\n",
    "        else:\n",
    "            break\n",
    "     \n",
    "    return word, code\n",
    "\n",
    "def get_vector(word, onset, vowel, codas):\n",
    "    word = str(word).upper()\n",
    "    \n",
    "    if word == \"NAN\":\n",
    "        word = \"NULL\"   \n",
    "    \n",
    "    vector = []\n",
    "    \n",
    "    for slot_set in [onset, vowel, codas]:\n",
    "        word, temp_code = get_vector_helper(word, slot_set)\n",
    "        vector = vector + temp_code\n",
    "    \n",
    "    return vector\n",
    "\n",
    "def get_graphemes2(word):\n",
    "    return get_vector(word, grapheme_onset, grapheme_vowel, grapheme_codas)\n",
    "\n",
    "def get_phonemes2(word):\n",
    "    word = word[1:-1]\n",
    "    return get_vector(word, phoneme_onset, phoneme_vowel, phoneme_codas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mappings for Graphemes\n",
    "grapheme_onset = ['Y', 'S', 'P', 'T', 'K', 'Q', 'C', 'B', 'D', 'G', 'F', 'V', 'J', 'Z',\n",
    "                  'L', 'M', 'N', 'R', 'W', 'H', 'CH', 'GH', 'GN', 'PH', 'PS', 'RH', 'SH', 'TH', 'TS', 'WH']\n",
    "grapheme_vowel = ['E', 'I', 'O', 'U', 'A', 'Y', 'AI', 'AU', 'AW', 'AY', 'EA', 'EE', 'EI',\n",
    "                  'EU', 'EW', 'EY', 'IE', 'OA', 'OE', 'OI', 'OO', 'OU', 'OW', 'OY', 'UE', 'UI', 'UY']\n",
    "grapheme_codas = ['H', 'R', 'L', 'M', 'N', 'B', 'D', 'G', 'C', 'X', 'F', 'V', 'J', 'S', 'Z', 'P', 'T', 'K', 'Q', 'BB', 'CH', 'CK', 'DD', 'DG',\n",
    "                  'FF', 'GG', 'GH', 'GN', 'KS', 'LL', 'NG', 'NN', 'PH', 'PP', 'PS', 'RR', 'SH', 'SL', 'SS', 'TCH', 'TH', 'TS', 'TT', 'ZZ', 'U', 'E', 'ES', 'ED']\n",
    "\n",
    "\n",
    "# Mappings for Phonemes\n",
    "phoneme_onset = ['s', 'S', 'C', 'z', 'Z', 'j', 'f', 'v', 'T', 'D',\n",
    "                 'p', 'b', 't', 'd', 'k', 'g', 'm', 'n', 'h', 'l', 'r', 'w', 'y']\n",
    "phoneme_vowel = ['a', 'e', 'i', 'o', 'u', '@',\n",
    "                 '^', 'A', 'E', 'I', 'O', 'U', 'W', 'Y']\n",
    "phoneme_codas = ['r', 'l', 'm', 'n', 'N', 'b', 'g', 'd', 'ps', 'ks',\n",
    "                 'ts', 's', 'z', 'f', 'v', 'p', 'k', 't', 'S', 'Z', 'T', 'D', 'C', 'j']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onset:\n",
      "Y\n",
      "P\n",
      "T\n",
      "C\n",
      "R\n",
      "vowel:\n",
      "coda:\n"
     ]
    }
   ],
   "source": [
    "word = \"crypt\"\n",
    "code = get_graphemes(word)\n",
    "onset = code[0:30]\n",
    "vowel = code[30:57]\n",
    "codas = code[57:57+48]\n",
    "print(\"onset:\")\n",
    "for i, j in zip(onset, grapheme_onset):\n",
    "    if i == 1:\n",
    "        print(j)\n",
    "print(\"vowel:\")\n",
    "for i, j in zip(vowel, grapheme_vowel):\n",
    "    if i == 1:\n",
    "        print(j)\n",
    "print(\"coda:\")\n",
    "for i, j in zip(codas, grapheme_codas):\n",
    "    if i == 1:\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onset:\n",
      "Y\n",
      "vowel:\n",
      "O\n",
      "U\n",
      "OU\n",
      "coda:\n"
     ]
    }
   ],
   "source": [
    "word = \"you\"\n",
    "code = get_graphemes2(word)\n",
    "onset = code[0:30]\n",
    "vowel = code[30:57]\n",
    "codas = code[57:57+48]\n",
    "print(\"onset:\")\n",
    "for i, j in zip(onset, grapheme_onset):\n",
    "    if i == 1:\n",
    "        print(j)\n",
    "print(\"vowel:\")\n",
    "for i, j in zip(vowel, grapheme_vowel):\n",
    "    if i == 1:\n",
    "        print(j)\n",
    "print(\"coda:\")\n",
    "for i, j in zip(codas, grapheme_codas):\n",
    "    if i == 1:\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(word):\n",
    "    code = get_graphemes(word)\n",
    "    code2 = get_graphemes2(word)\n",
    "    for i, j in zip(code, code2):\n",
    "        if i != j:\n",
    "            #print(\"Different\", word)\n",
    "            return -1\n",
    "    #print(\"Same\")\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, plaut_loader, plaut_anc_loader, anc_loader, probe_loader, folder, lr=0.001):\n",
    "    # define loss function and optimizer\n",
    "    criterion = nn.BCELoss(reduction='none')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Initialize arrays to store epochs, train loss\n",
    "    epochs, losses = [], []\n",
    "    \n",
    "    # Select word types to calculate accuracy for\n",
    "    types = [\"HEC\", \"HRI\", \"HFE\", \"LEC\", \"LFRI\", \"LFEEXPT\"] # calculate accuracy of these types\n",
    "    anc_types = [\"ANC_REG\", \"ANC_EXC\", \"ANC_AMB\"]\n",
    "    probe_types = [\"PRO_REG\", \"PRO_EXC\", \"PRO_AMB\"]\n",
    "    \n",
    "    # Initialize arrays to store accuracy of plaut dataset, anchors, probes\n",
    "    acc = [[], [], [], []]\n",
    "    anc_acc = [[] for i in anc_types]\n",
    "    probe_acc = [[] for i in probe_types]\n",
    "    \n",
    "    for epoch in range(600):\n",
    "        if epoch < 500: # use only plaut dataset for first 500 epochs\n",
    "            data_loader = plaut_loader\n",
    "        else: # after, train with both plaut + anchors\n",
    "            data_loader = plaut_anc_loader\n",
    "        \n",
    "        avg_loss = 0 # initialize avg loss\n",
    "        for i, data in enumerate(data_loader): \n",
    "            # extract frequency, inputs, labels\n",
    "            freq = data[\"frequency\"].float().view(-1, 1) # reshape to [batch_size x 1] to match output size\n",
    "            inputs = data[\"graphemes\"].float()\n",
    "            labels = data[\"phonemes\"].float()\n",
    "            \n",
    "            #forward pass + backward pass + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = (loss*freq).mean() # scale loss by frequency, then find mean\n",
    "            avg_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # calculate loss and save loss to array\n",
    "        losses.append(avg_loss)\n",
    "        epochs.append(epoch+1)\n",
    "        \n",
    "        # calculate accuracy over the different types for plaut dataset\n",
    "        temp_acc = get_accuracy(model, plaut_loader, types)\n",
    "        acc[0].append((temp_acc[0]+temp_acc[1])/2) # average of HFR consistent and inconsistent\n",
    "        acc[1].append(temp_acc[2]) # HFE\n",
    "        acc[2].append((temp_acc[3]+temp_acc[4])/2) # average of LFR consistent and inconsistent\n",
    "        acc[3].append(temp_acc[5]) # LFE\n",
    "        \n",
    "        # calculate accuracy over the different types for anchors\n",
    "        temp_acc = get_accuracy(model, anc_loader, anc_types, vowels_only=True)\n",
    "        for i in range(len(anc_types)):\n",
    "            anc_acc[i].append(temp_acc[i])\n",
    "            \n",
    "        # calculate accuracy over the different types for probes\n",
    "        temp_acc = get_accuracy(model, probe_loader, probe_types, vowels_only=True)\n",
    "        for i in range(len(probe_types)):\n",
    "            probe_acc[i].append(temp_acc[i])\n",
    "        \n",
    "        # print stats every 5 epochs\n",
    "        if epoch % 1 == 0:\n",
    "            print(\"[EPOCH %d] loss: %.6f\" % (epoch+1, avg_loss))\n",
    "        \n",
    "        # plot loss every 5 epochs\n",
    "        if epoch % 50 == 49:\n",
    "            make_plot(epochs, [losses], [\"Train Loss\"], \"Epoch\", \"Loss\", \"Training Loss\")\n",
    "            make_plot(epochs, acc, [\"HFR\", \"HFE\", \"LFR\", \"LFE\"], \"Epoch\", \"Accuracy\", \"Training Accuracy\")\n",
    "            make_plot(epochs, anc_acc, anc_types, \"Epoch\", \"Accuracy\", \"Anchor Accuracy\")\n",
    "            make_plot(epochs, probe_acc, probe_types, \"Epoch\", \"Accuracy\", \"Probe Accuracy\")\n",
    "            \n",
    "\n",
    "    # plot final loss curve and save\n",
    "    plt.figure()\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.plot(losses, label=\"Training Loss\")\n",
    "    plt.savefig(rootdir+\"/lossplot_final.png\", dpi=150)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new folder for every run\n",
    "path = Path(os.getcwd()).parent #get parent (Plaut_Model) directory filepath\n",
    "now = datetime.datetime.now()\n",
    "date = now.strftime(\"%b\").lower()+now.strftime(\"%d\")\n",
    "i = 1\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        rootdir = str(path)+\"/results/\"+date+\"_test\"+'{:02d}'.format(i)\n",
    "        os.mkdir(rootdir)\n",
    "        break\n",
    "    except:\n",
    "        i += 1\n",
    "\n",
    "\n",
    "print(\"Test Results saved in :\", rootdir)\n",
    "\n",
    "torch.manual_seed(1) # initialize random seed\n",
    "model = plaut_net() # initialize model\n",
    "train(model, plaut_loader, plaut_anc_loader, anc_loader, probe_loader, rootdir, lr=0.1) # train!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain list of categories in dataset, and add \"All\" for overall accuracy\n",
    "types = list(plaut_ds.df[\"type\"].unique())\n",
    "types.append(\"All\")\n",
    "    \n",
    "accuracy = get_accuracy(model, plaut_loader, types)\n",
    "\n",
    "\n",
    "# plot in bar graph\n",
    "plt.bar(types, accuracy)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.xlabel(\"Type\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy by Type\")\n",
    "plt.savefig(\"../test/\"+rootdir+\"/accuracy_chart_final.png\", dpi=150)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the accuracy of a particular category\n",
    "def get_accuracy2 (model, train_loader, cat='All'):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in enumerate (train_loader): # get batch from dataloader\n",
    "        # extract inputs, labels, type from batch\n",
    "        inputs = data[\"graphemes\"].float()\n",
    "        labels = data[\"phonemes\"].float()\n",
    "        types = pd.DataFrame(data[\"type\"])\n",
    "        \n",
    "        outputs = model(inputs) # find prediction using model\n",
    "        outputs = outputs.round() # round output to 0 or 1\n",
    "        compare = torch.eq(outputs, labels).sum(dim=1) # compare with labels\n",
    "        \n",
    "        if cat == 'All':\n",
    "            correct += torch.eq(compare, 61).sum().item() # count as correct if all 61 elements match label\n",
    "            total += len(compare)\n",
    "        else:\n",
    "            types = types.apply(lambda x: x == cat) # check for desired type\n",
    "            compare = pd.DataFrame(compare)\n",
    "            correct += ((types == True) & (compare == 61)).sum()[0] # count as correct if desired type AND all 61 elements match total\n",
    "            total += (types==True).sum()[0] # count all of the desired type\n",
    "    \n",
    "    return correct/(total) # return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_vowels (model, train_loader, cat=['REG', 'EXC', 'AMB']):\n",
    "    correct = [0, 0, 0]\n",
    "    total = [0, 0, 0]\n",
    "    for i, data in enumerate (train_loader):\n",
    "        inputs = data[\"graphemes\"].float()\n",
    "        labels = data[\"phonemes\"].float()\n",
    "        labels = labels[:, len(phoneme_onset):len(phoneme_onset)+len(phoneme_vowel)]\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs[:, len(phoneme_onset):len(phoneme_onset)+len(phoneme_vowel)]\n",
    "        outputs = torch.sigmoid(outputs).round()\n",
    "        compare = torch.eq(outputs, labels).sum(dim=1)\n",
    "        for i in range(len(cat)):\n",
    "            types = pd.DataFrame(data[\"type\"])\n",
    "            #print(types)\n",
    "            types = types.apply(lambda x: x == cat[i])\n",
    "            #print(types)\n",
    "            #break\n",
    "            compare = pd.DataFrame(compare)\n",
    "            correct[i] += ((types == True) & (compare == len(phoneme_vowel))).sum()[0]\n",
    "            total[i] += (types==True).sum()[0]\n",
    "    return correct, total"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
